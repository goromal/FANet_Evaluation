{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FANet_trainer_WITH_TIME.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goromal/FANet_Evaluation/blob/main/FANet_trainer_WITH_TIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc0hy8Su-w9N"
      },
      "source": [
        "# Dayne Howard, David Elatov, Andrew Torgesen, MIT, 6.862, Spring 2021\n",
        "# Parts of this code were based on code developed by 6.036 staff for student use\n",
        "# The FANet model here was modified slightly to include time effects.\n",
        "# Original FANet Paper: arXiv:2007.03815v2 [cs.CV] 9 Jul 2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS7i5GXD9bmD",
        "outputId": "bf20e4ef-aa8d-4905-b9d5-294c1889700f"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvffU9fp9iGD",
        "outputId": "284e3b11-9a9a-404c-f6e9-f6f5655f4d79"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inc0Wx9D9pRn"
      },
      "source": [
        "### Repository\n",
        "\n",
        "Mount drive, clone repo, navigate to repo, and change working directory to access repo files. **Run ONCE per computing session.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyYm5Oqx9npv",
        "outputId": "f4d26ec0-a95d-4fae-e2d6-ec3be5abac1a"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import h5py\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive\n",
        "#Select the folder where the data is\n",
        "%cd TartanAir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive\n",
            "/content/gdrive/.shortcut-targets-by-id/13SoHYEacjxfjCnzL_FlI8YHqm3zFzMva/TartanAir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjU4xS3c9GPE",
        "outputId": "18d363b7-d3d5-4df1-a0a6-89140def59ba"
      },
      "source": [
        "! pip install oyaml\n",
        "! pip install torchstat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting oyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/37/aa/111610d8bf5b1bb7a295a048fc648cec346347a8b0be5881defd2d1b4a52/oyaml-1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from oyaml) (3.13)\n",
            "Installing collected packages: oyaml\n",
            "Successfully installed oyaml-1.0\n",
            "Collecting torchstat\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/fe/f483b907ca80c90f189cd892bb2ce7b2c256010b30314bbec4fc17d1b5f1/torchstat-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.8.1+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchstat) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchstat) (1.15.0)\n",
            "Installing collected packages: torchstat\n",
            "Successfully installed torchstat-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm-MJyV3uMMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c999f41-4713-42d5-9935-001e0c62405a"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib.image import imread\n",
        "import os\n",
        "from random import sample\n",
        "# We'll use the PyTorch Framework\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchstat import stat\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '/content/gdrive/MyDrive/FANet_Evaluation/evaluation') # so that the evaluation pipeline's internal imports work\n",
        "import oyaml as yaml\n",
        "from PIL import Image # for image resizing\n",
        "\n",
        "# For displaying images later\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "# Set a random seed for predictable behavior\n",
        "torch.manual_seed(6036)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd30eb23550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFglcoNq86aD"
      },
      "source": [
        "# Argument class to instantiate a model\n",
        "class ModelTrainArgs(object):\n",
        "    def __init__(self):\n",
        "        # MODEL ARGS\n",
        "        self.img_width = 640\n",
        "        self.img_height = 480\n",
        "        self.num_channels = 3 # 3 channels for color images\n",
        "        # data dir contains pre-processed weights.npy, X_train.npy, Y_train.npy, X_val.npy, Y_val.npy\n",
        "        self.data_dir = '/content/gdrive/MyDrive/full_cityscapes_res/' # DATA LOCATED IN \"My Drive/full_cityscapes_res\"\n",
        "        self.weighted_loss = True\n",
        "        self.batch_size = 16\n",
        "        self.learning_rate = 0.0001\n",
        "        \n",
        "        # TRAIN ARGS\n",
        "        self.num_classes = 11 # for AirSim\n",
        "\n",
        "# Set parameters\n",
        "args = ModelTrainArgs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDFBpYHY7wm1",
        "outputId": "5864a00c-07c1-4da1-b746-6a316575e350"
      },
      "source": [
        "# Load in the data as numpy files. X is input, Y is target\n",
        "# All data (train, validation, test) included here.\n",
        "# N=number of data oints\n",
        "# C=number of channels\n",
        "# W=Width\n",
        "# H=Height\n",
        "# X: (N, C, W, H)\n",
        "# Y: (N, W, H)\n",
        "X = np.load('X.npy')\n",
        "Y = np.load('Y.npy')\n",
        "\n",
        "print('Loaded X with size ' + str(X.shape))\n",
        "print('Loaded Y with size ' + str(Y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded X with size (8688, 3, 480, 640)\n",
            "Loaded Y with size (8688, 60, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsw5882LLKzF"
      },
      "source": [
        "# Specify how many previous frames, T, you want to include\n",
        "# in the temporal aggregation context. \n",
        "# Change it in the FastAttModule to match self.T\n",
        "T = 4\n",
        "\n",
        "num_data_points = X.shape[0]\n",
        "\n",
        "# All indices available are spread out by T+1.\n",
        "ind = [*range(T,num_data_points,T+1)]\n",
        "\n",
        "# chooses indices of about 10% of the points randomly for validation\n",
        "val_ind = np.asarray(sample(ind,int(num_data_points/(T+1))//10))\n",
        "for k in val_ind:\n",
        "  ind.remove(k)\n",
        "\n",
        "# chooses indices of about 10% of the points randomly for testing\n",
        "test_ind = np.asarray(sample(ind,int(num_data_points/(T+1))//10))\n",
        "for k in test_ind:\n",
        "  ind.remove(k)\n",
        "\n",
        "# The rest of the indices go to training\n",
        "train_ind = np.asarray(sample(ind,len(ind)))\n",
        "\n",
        "#This splits the indices into batches of 16.\n",
        "train_ind = np.array_split(train_ind, len(train_ind)//16)\n",
        "val_ind = np.array_split(val_ind, len(val_ind)//16)\n",
        "test_ind = np.array_split(test_ind, len(test_ind)//16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4Sw-MDpqbqU",
        "outputId": "3b6daf43-616b-4c35-a2cb-f96dbeb7e658"
      },
      "source": [
        "print(len(val_ind))\n",
        "print(len(test_ind))\n",
        "print(len(train_ind))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "13\n",
            "108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkR-FQjblR3c"
      },
      "source": [
        "# A function which creates a \"one_hot\" tensor from a tensor with class labels\n",
        "# starting at 0\n",
        "def to_one_hot(tensor,device,nClasses=args.num_classes):\n",
        "    n,h,w = tensor.size()\n",
        "    one_hot = torch.zeros(n,nClasses,h,w).to(device).scatter_(1,tensor.view(n,1,h,w),1)\n",
        "    return one_hot\n",
        "\n",
        "# Mean Intersection Over Union\n",
        "# This variant of mIoU gives even weight per pixel, not even weight per class\n",
        "class mIoULoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True, n_classes=args.num_classes):\n",
        "        super(mIoULoss, self).__init__()\n",
        "        self.classes = n_classes\n",
        "\n",
        "    def forward(self, inputs, target_oneHot):\n",
        "      # inputs => N x Classes x H x W\n",
        "    \t# target_oneHot => N x Classes x H x W\n",
        "      N = inputs.size()[0]\n",
        "      \n",
        "      # predicted probabilities for each pixel along channel\n",
        "      inputs = torch.nn.functional.one_hot(inputs.argmax(1), num_classes=args.num_classes).permute(0,3,1,2)\n",
        "\n",
        "      # Numerator Product\n",
        "      inter = inputs * target_oneHot\n",
        "\n",
        "      ## Sum over all pixels N x C x H x W => N x C\n",
        "      #inter = inter.view(N,self.classes,-1).sum(2)\n",
        "      ## Sum over all pixels N x C x H x W => N\n",
        "      inter = torch.sum(inter,(1,2,3))\n",
        "\n",
        "      #Denominator \n",
        "      union= inputs + target_oneHot - (inputs*target_oneHot)\n",
        "\n",
        "      ## Sum over all pixels N x C x H x W => N\n",
        "      union = torch.sum(union,(1,2,3))\n",
        "\n",
        "      loss = inter/union\n",
        "      ## Return average loss over classes and batch\n",
        "      return np.nanmean(np.asarray(loss.cpu()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_a9JayvzGHv"
      },
      "source": [
        "def train(model, device, X, Y,indices, optimizer, T):\n",
        "  '''\n",
        "  Function for training our networks. One call to train() performs a single\n",
        "  epoch for training.\n",
        "  model: an instance of our model\n",
        "  X: All input data as numpy array\n",
        "  Y: All target data as numpy array\n",
        "  indices: the indices to pull from X and Y, separated into a list of numpy \n",
        "  arrays. Each of these sublists is effectively a batch \n",
        "  device: either \"cpu\" or \"cuda\", depending on if you're running with GPU support\n",
        "  optimizer: optimizer used for training\n",
        "  T: How many previous frames are aggregated\n",
        "  '''\n",
        "\n",
        "  # Set the model to training mode.\n",
        "  model.train()\n",
        "\n",
        "  # initialze the optimizer (the optimizer implements SGD)\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #we'll keep adding the loss of each batch to total_loss, so we can calculate\n",
        "  #the average loss at the end of the epoch.\n",
        "  total_loss = 0\n",
        "  total_mIoU = 0\n",
        "  numBatches = int(len(indices))\n",
        "\n",
        "  # We'll iterate through each batch. One call of train() trains for 1 epoch.\n",
        "  # batch_ind: an integer representing which batch number we're on\n",
        "\n",
        "  for batch_ind in range(numBatches):\n",
        "    batch_size = len(indices[batch_ind])\n",
        "    mIoU = 0\n",
        "    loss_value = 0\n",
        "\n",
        "    for i in indices[batch_ind]:  #Loop through the member of the batch    \n",
        "      # Normalize the input data here, since doing it all at once is too \n",
        "      # much memory. T previous time frames are included\n",
        "      input = torch.from_numpy(X[i-T:i+1,:,:,:]/255)\n",
        "      target = torch.from_numpy(Y[i-T:i+1,:,:])\n",
        "\n",
        "      # This line sends data to GPU if you're using a GPU\n",
        "      input = input.to(device, dtype=torch.float)\n",
        "      target = target.type(torch.LongTensor).to(device)    \n",
        "\n",
        "      # feed our input through the network\n",
        "      output = model.forward(input)\n",
        "      \n",
        "      loss_function = nn.CrossEntropyLoss()\n",
        "      # loss is only based on the frames after T. Current code setup means\n",
        "      # this will just be a single frame.\n",
        "      loss = loss_function(output[T:],target[T:])\n",
        "      loss_value += loss.item()\n",
        "\n",
        "      #Calculate the mIoU\n",
        "      mIoU_function = mIoULoss()\n",
        "      target_onehot = to_one_hot(target, device)\n",
        "      mIoU += mIoU_function(output[T:], target_onehot[T:]).item()\n",
        "\n",
        "      # Perform backprop. Gradients are retained through all members of the batch\n",
        "      loss.backward()\n",
        "    \n",
        "    # after finishing the batch, take a step and reset\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    loss_value = loss_value / batch_size\n",
        "    mIoU       = mIoU / batch_size\n",
        "    total_loss += loss_value\n",
        "    total_mIoU += mIoU\n",
        "  total_loss /= (numBatches)\n",
        "  total_mIoU /= (numBatches)\n",
        "\n",
        "  return (total_loss, total_mIoU)\n",
        "\n",
        "def test(model, device, T, X, Y, indices):\n",
        "  '''\n",
        "  Function for testing our models. One call to test() runs through every\n",
        "  datapoint in our dataset once.\n",
        "  model: an instance of our model\n",
        "  device: either \"cpu\" or \"cuda:0\", depending on if you're running with GPU support\n",
        "  T: How many previous frames are aggregated\n",
        "  X: All input data as numpy array\n",
        "  Y: All target data as numpy array\n",
        "  indices: the indices to pull from X and Y, separated into a list of numpy \n",
        "  arrays. Each of these sublists is effectively a batch \n",
        "  '''\n",
        "\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # we'll keep track of total loss to calculate the average later\n",
        "  total_loss = 0\n",
        "  total_mIoU = 0\n",
        "  numBatches = int(len(indices))\n",
        "\n",
        "  #don't perform backprop if testing\n",
        "  with torch.no_grad():\n",
        "    # iterate thorugh each test image\n",
        "    for batch_ind in range(numBatches):\n",
        "      batch_size = len(indices[batch_ind])\n",
        "      mIoU = 0\n",
        "      loss_value = 0\n",
        "\n",
        "      for i in indices[batch_ind]:      \n",
        "        # Normalize the input data here, since doing it all at once is too \n",
        "        # much memory\n",
        "        input = torch.from_numpy(X[i-T:i+1,:,:,:]/255)\n",
        "        target = torch.from_numpy(Y[i-T:i+1,:,:])\n",
        "\n",
        "        # (input, target) = readBatch(namelist[i:(i+args.batch_size)])\n",
        "        # This line sends data to GPU if you're using a GPU\n",
        "        input = input.to(device, dtype=torch.float)\n",
        "        target = target.type(torch.LongTensor).to(device)    \n",
        "\n",
        "        # feed our input through the network\n",
        "        output = model.forward(input)\n",
        "        \n",
        "        loss_function = nn.CrossEntropyLoss()\n",
        "        loss = loss_function(output[T:],target[T:])\n",
        "        loss_value += loss.item()\n",
        "\n",
        "        #Calculate the mIoU\n",
        "        mIoU_function = mIoULoss()\n",
        "        target_onehot = to_one_hot(target, device)\n",
        "        mIoU += mIoU_function(output[T:], target_onehot[T:]).item()\n",
        "\n",
        "      #accumulate loss to later calculate the average\n",
        "      loss_value = loss_value / batch_size\n",
        "      mIoU       = mIoU / batch_size\n",
        "      total_loss += loss_value\n",
        "      total_mIoU += mIoU        \n",
        "\n",
        "  total_loss /= (numBatches)\n",
        "  total_mIoU /= (numBatches)\n",
        "  return (total_loss, total_mIoU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA3JLqV38kEq"
      },
      "source": [
        "#####################  FANet Model  ######################################\n",
        "class BatchNorm2d(nn.BatchNorm2d):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, num_features, activation='none'):\n",
        "        super(BatchNorm2d, self).__init__(num_features=num_features)\n",
        "        if activation == 'leaky_relu':\n",
        "            self.activation = nn.LeakyReLU()\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x:x\n",
        "        else:\n",
        "            raise Exception(\"Accepted activation: ['leaky_relu']\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.activation(x)\n",
        "\n",
        "up_kwargs = {'mode': 'bilinear', 'align_corners': True}\n",
        "\n",
        "\n",
        "class FANet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 nclass=args.num_classes,\n",
        "                 backbone='resnet18',\n",
        "                 norm_layer=BatchNorm2d):\n",
        "        super(FANet, self).__init__()\n",
        "\n",
        "        self.norm_layer = norm_layer\n",
        "        self._up_kwargs = up_kwargs\n",
        "        self.nclass = nclass\n",
        "        self.backbone = backbone\n",
        "        if backbone == 'resnet18':\n",
        "            self.expansion = 1\n",
        "            self.resnet = Resnet18(norm_layer=norm_layer)\n",
        "        elif backbone == 'resnet34':\n",
        "            self.expansion = 1\n",
        "            self.resnet = Resnet34(norm_layer=norm_layer)\n",
        "        elif backbone == 'resnet50':\n",
        "            self.expansion = 4\n",
        "            self.resnet = Resnet50(norm_layer=norm_layer)\n",
        "        elif backbone == 'resnet101':\n",
        "            self.expansion = 4\n",
        "            self.resnet = Resnet101(norm_layer=norm_layer)\n",
        "        elif backbone == 'resnet152':\n",
        "            self.expansion = 4\n",
        "            self.resnet = Resnet152(norm_layer=norm_layer)\n",
        "        else:\n",
        "            raise RuntimeError('unknown backbone: {}'.format(backbone))\n",
        "\n",
        "        self.fam_32 = FastAttModule(512*self.expansion,256,128,norm_layer=norm_layer)\n",
        "        self.fam_16 = FastAttModule(256*self.expansion,256,128,norm_layer=norm_layer)\n",
        "        self.fam_8 = FastAttModule(128*self.expansion,256,128,norm_layer=norm_layer)\n",
        "        self.fam_4 = FastAttModule(64*self.expansion,256,128,norm_layer=norm_layer)\n",
        "\n",
        "        self.clslayer  = FPNOutput(256, 256, nclass,norm_layer=norm_layer)\n",
        "\n",
        "    def forward(self, x, lbl=None):\n",
        "\n",
        "        _, _, h, w = x.size()\n",
        "\n",
        "        feat4, feat8, feat16, feat32 = self.resnet(x)\n",
        "\n",
        "        upfeat_32, smfeat_32 = self.fam_32(feat32,None,True,True)\n",
        "        upfeat_16, smfeat_16 = self.fam_16(feat16,upfeat_32,True,True)\n",
        "        upfeat_8             = self.fam_8(feat8,upfeat_16,True,False)\n",
        "        smfeat_4             = self.fam_4(feat4,upfeat_8,False,True)\n",
        "\n",
        "        x = self._upsample_cat(smfeat_16, smfeat_4)\n",
        "\n",
        "        outputs = self.clslayer(x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _upsample_cat(self, x1, x2):\n",
        "        '''Upsample and concatenate feature maps.\n",
        "        '''\n",
        "        _,_,H,W = x2.size()\n",
        "        x1 = F.interpolate(x1, (H,W), **self._up_kwargs)\n",
        "        x = torch.cat([x1,x2],dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Module):\n",
        "    def __init__(self, in_chan, out_chan, ks=3, stride=1, padding=1, norm_layer=None, activation='leaky_relu',*args, **kwargs):\n",
        "        super(ConvBNReLU, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_chan,\n",
        "                out_chan,\n",
        "                kernel_size = ks,\n",
        "                stride = stride,\n",
        "                padding = padding,\n",
        "                bias = False)\n",
        "        self.norm_layer = norm_layer\n",
        "        if self.norm_layer is not None:\n",
        "            self.bn = norm_layer(out_chan, activation=activation)\n",
        "        else:\n",
        "            self.bn =  lambda x:x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FPNOutput(nn.Module):\n",
        "    def __init__(self, in_chan, mid_chan, n_classes, norm_layer=None, *args, **kwargs):\n",
        "        super(FPNOutput, self).__init__()\n",
        "        self.norm_layer = norm_layer\n",
        "        self.conv = ConvBNReLU(in_chan, mid_chan, ks=3, stride=1, padding=1, norm_layer=norm_layer)\n",
        "        self.conv_out = nn.Conv2d(mid_chan, n_classes, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.conv_out(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FastAttModule(nn.Module):\n",
        "    def __init__(self, in_chan, mid_chn=256, out_chan=128, norm_layer=None, *args, **kwargs):\n",
        "        super(FastAttModule, self).__init__()\n",
        "        self.norm_layer = norm_layer\n",
        "        self._up_kwargs = up_kwargs\n",
        "        mid_chn = int(in_chan/2)        \n",
        "        self.w_qs = ConvBNReLU(in_chan, 32, ks=1, stride=1, padding=0, norm_layer=norm_layer, activation='none')\n",
        "\n",
        "        self.w_ks = ConvBNReLU(in_chan, 32, ks=1, stride=1, padding=0, norm_layer=norm_layer, activation='none')\n",
        "\n",
        "        self.w_vs = ConvBNReLU(in_chan, in_chan, ks=1, stride=1, padding=0, norm_layer=norm_layer)\n",
        "\n",
        "        self.latlayer3 = ConvBNReLU(in_chan, in_chan, ks=1, stride=1, padding=0, norm_layer=norm_layer)\n",
        "\n",
        "        self.up = ConvBNReLU(in_chan, mid_chn, ks=1, stride=1, padding=1, norm_layer=norm_layer)\n",
        "        self.smooth = ConvBNReLU(in_chan, out_chan, ks=3, stride=1, padding=1, norm_layer=norm_layer)\n",
        "\n",
        "        # Modification to original FANet Github code.\n",
        "        # This T should match the T declared at the top of this code\n",
        "        self.T = 4\n",
        "          \n",
        "    def forward(self, feat, up_fea_in,up_flag, smf_flag):\n",
        "        \n",
        "        query = self.w_qs(feat)\n",
        "        key   = self.w_ks(feat)\n",
        "        value = self.w_vs(feat)\n",
        "\n",
        "        N,C,H,W = feat.size()\n",
        "\n",
        "        query_ = query.view(N,32,-1).permute(0, 2, 1)\n",
        "        query = F.normalize(query_, p=2, dim=2, eps=1e-12)\n",
        "\n",
        "        key_   = key.view(N,32,-1)\n",
        "        key   = F.normalize(key_, p=2, dim=1, eps=1e-12)\n",
        "\n",
        "        value = value.view(N,C,-1).permute(0, 2, 1)\n",
        "\n",
        "        f = torch.matmul(key, value)\n",
        "\n",
        "        #Modification to original FANet Github code:\n",
        "        #Add in the hisotry key and value maps\n",
        "        batch_s = key.shape[0]\n",
        "        for idx in range(self.T,batch_s):\n",
        "          for t in range(idx-self.T,idx):\n",
        "            f += torch.matmul(key[t,:,:], value[t,:,:])\n",
        "\n",
        "        y = torch.matmul(query, f)\n",
        "        y = y.permute(0, 2, 1).contiguous()\n",
        "\n",
        "        y = y.view(N, C, H, W)\n",
        "        W_y = self.latlayer3(y)\n",
        "        p_feat = W_y + feat\n",
        "\n",
        "        if up_flag and smf_flag:\n",
        "            if up_fea_in is not None:\n",
        "                p_feat = self._upsample_add(up_fea_in, p_feat)\n",
        "            up_feat = self.up(p_feat)\n",
        "            smooth_feat = self.smooth(p_feat)\n",
        "            return up_feat, smooth_feat\n",
        "\n",
        "        if up_flag and not smf_flag:\n",
        "            if up_fea_in is not None:\n",
        "                p_feat = self._upsample_add(up_fea_in, p_feat)\n",
        "            up_feat = self.up(p_feat)\n",
        "            return up_feat\n",
        "\n",
        "        if not up_flag and smf_flag:\n",
        "            if up_fea_in is not None:\n",
        "                p_feat = self._upsample_add(up_fea_in, p_feat)\n",
        "            smooth_feat = self.smooth(p_feat)\n",
        "            return smooth_feat\n",
        "\n",
        "    def _upsample_add(self, x, y):\n",
        "        '''Upsample and add two feature maps.\n",
        "        '''\n",
        "        _,_,H,W = y.size()\n",
        "        return F.interpolate(x, (H,W), **self._up_kwargs) + y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6I9NvEea8qf"
      },
      "source": [
        "model_urls = {'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth'}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                     padding=0, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_chan, out_chan, stride=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.norm_layer = norm_layer\n",
        "        self.conv1 = conv3x3(in_chan, out_chan, stride)\n",
        "        self.bn1 = norm_layer(out_chan, activation='leaky_relu')\n",
        "        self.conv2 = conv3x3(out_chan, out_chan)\n",
        "        self.bn2 = norm_layer(out_chan, activation='none')\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = None\n",
        "        if in_chan != out_chan or stride != 1:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_chan, out_chan,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                norm_layer(out_chan, activation='none'),\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        shortcut = x\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "\n",
        "        out_ = shortcut + out\n",
        "        out_ = self.relu(out_)\n",
        "        return out_\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_chan, out_chan, stride=1, base_width=64, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        width = int(out_chan*(base_width / 64.)) * 1\n",
        "        self.norm_layer = norm_layer\n",
        "        self.conv1 = conv1x1(in_chan, width)\n",
        "        self.bn1 = norm_layer(width, activation='leaky_relu')\n",
        "        self.conv2 = conv3x3(width, width, stride)\n",
        "        self.bn2 = norm_layer(width, activation='leaky_relu')\n",
        "        self.conv3 = conv1x1(width, out_chan * self.expansion)\n",
        "        self.bn3 = norm_layer(out_chan * self.expansion, activation='none')\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = None\n",
        "        if in_chan != out_chan*self.expansion or stride != 1:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_chan, out_chan*self.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                norm_layer(out_chan*self.expansion, activation='none'),\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        shortcut = x\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "\n",
        "        out_ = shortcut +out\n",
        "        out_ = self.relu(out_)\n",
        "\n",
        "        return out_\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, strides, norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.norm_layer = norm_layer\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = norm_layer(64, activation='leaky_relu')\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.inplanes = 64\n",
        "        self.layer1 = self.create_layer(block,   64, bnum=layers[0], stride=strides[0], norm_layer=norm_layer)\n",
        "        self.layer2 = self.create_layer(block,  128, bnum=layers[1], stride=strides[1], norm_layer=norm_layer)\n",
        "        self.layer3 = self.create_layer(block,  256, bnum=layers[2], stride=strides[2], norm_layer=norm_layer)\n",
        "        self.layer4 = self.create_layer(block,  512, bnum=layers[3], stride=strides[3], norm_layer=norm_layer)\n",
        "\n",
        "    def create_layer(self, block , out_chan, bnum, stride=1,norm_layer=None):\n",
        "        layers = [block(self.inplanes, out_chan, stride=stride, norm_layer=norm_layer)]\n",
        "        self.inplanes = out_chan*block.expansion\n",
        "        for i in range(bnum-1):\n",
        "            layers.append(block(self.inplanes, out_chan, stride=1, norm_layer=norm_layer))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        feat4 = self.layer1(x)\n",
        "        feat8 = self.layer2(feat4) # 1/8\n",
        "        feat16 = self.layer3(feat8) # 1/16\n",
        "        feat32 = self.layer4(feat16) # 1/32\n",
        "        return feat4, feat8, feat16, feat32\n",
        "\n",
        "    def init_weight(self,state_dict):\n",
        "        self_state_dict = self.state_dict()\n",
        "        for k, v in state_dict.items():\n",
        "            if 'fc' in k: continue\n",
        "            self_state_dict.update({k: v})\n",
        "        self.load_state_dict(self_state_dict, strict=True)\n",
        "\n",
        "def Resnet18(pretrained=True, norm_layer=None, **kwargs):\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2],[2, 2, 2, 2], norm_layer=norm_layer)\n",
        "    if pretrained:\n",
        "        model.init_weight(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JSB4PeQKEv1"
      },
      "source": [
        "def ten2img(my_tensor,filename):\n",
        "  '''Call this function to save a segmentation image.\n",
        "  my_tensor = [labels, height, width]. labels start at 0 '''\n",
        "\n",
        "  listofColors = ['black','red','lime','cyan','sandybrown','crimson',\n",
        "                  'yellow', 'purple','maroon','fuchsia','olive']\n",
        "  labels, h, w = my_tensor.shape\n",
        "  my_image = np.zeros((h,w,3))\n",
        "  for i in range(labels):\n",
        "    col = matplotlib.colors.to_rgb(listofColors[i])\n",
        "    my_image += np.tensordot(my_tensor[i,:,:],col,0)\n",
        "  image = Image.fromarray((my_image*255).astype(np.uint8)).resize(size=(1024,512)).save(filename + '.png',format='PNG')\n",
        "\n",
        "def saveimg(network, X,Y,indices, filename):\n",
        "  '''Calls ten2img function above to save a generated segmentation map and its target'''\n",
        "    network.eval()\n",
        "    with torch.no_grad():\n",
        "      i = indices[0]\n",
        "      input = torch.from_numpy(X[i-T:i+1,:,:,:]/255)\n",
        "      target = torch.from_numpy(Y[i-T:i+1,:,:])\n",
        "      input = input.to(device, dtype=torch.float)\n",
        "\n",
        "      output = network(input)[T].cpu()\n",
        "      output_one_hot = np.asarray(torch.nn.functional.one_hot(output.argmax(0), num_classes=args.num_classes).permute(2,0,1))\n",
        "      \n",
        "      target = target.type(torch.LongTensor)\n",
        "      target_one_hot = np.asarray(to_one_hot(target, \"cpu\")[T])\n",
        "\n",
        "      ten2img(output_one_hot,'prediction_'+filename)\n",
        "      ten2img(target_one_hot,'target_'+filename)\n",
        "  \n",
        "      return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa0pGtld8pDf"
      },
      "source": [
        "# Check if using CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create an instance of our CNN\n",
        "network = FANet(backbone='resnet18').to(device)\n",
        "\n",
        "# initialize our optimizer. We'll use Adam\n",
        "optimizer = torch.optim.Adam(network.parameters())\n",
        "\n",
        "epochs = 15\n",
        "\n",
        "# Train the CNN\n",
        "for epoch in range(1, epochs+1):\n",
        "    (train_loss, train_mIoU) = train(network, device, X, Y, train_ind , optimizer, T)\n",
        "    (val_loss, val_mIoU) = test(network, device, T, X, Y , val_ind)\n",
        "    print('Train Epoch: {:02d} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTraining mIoU: {:.6f} \\tValidation mIoU: {:.6f}'.format(epoch, train_loss, val_loss, train_mIoU, val_mIoU))\n",
        "    if (epoch==1 or epoch==5 or epoch==7 or epoch==10 or epoch==15):\n",
        "      saveimg(network, X,Y,train_ind[0], 'T3_attemptA_mixedbatches_train_epoch_'+str(epoch))\n",
        "      saveimg(network, X,Y,val_ind[0], 'T3_attemptA_mixedbatches_val_epoch_'+str(epoch))\n",
        "\n",
        "# Test the CNN\n",
        "(test_loss, test_mIoU) = test(network, device, T, X, Y , test_ind)\n",
        "print('Test Loss: {:.6f} \\t Test mIoU: {:.6f}'.format(test_loss, test_mIoU))\n",
        "saveimg(network, X,Y,test_ind[0], 'T3_attemptA_mixedbatches_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHQrZhJbtx_s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}