{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/goromal/FANet_Evaluation/blob/main/fanet_eval_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvVGRtJx3XgV"
   },
   "source": [
    "# FANet Evaluation - 6.862 Project\n",
    "\n",
    "\n",
    "\n",
    "*   David Elatov\n",
    "*   Dayne Howard\n",
    "*   Andrew Torgesen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwoEgKvm3cjE"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ajqG5KQ_kHn"
   },
   "source": [
    "### CUDA\n",
    "\n",
    "1. Go to **Menu > Runtime > Change runtime type** and make sure that GPU is enabled.\n",
    "2. Run the commands below to ensure that the GPU (and CUDA) is operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pZ2TKFFACfl",
    "outputId": "bc513046-c6b4-4031-ae06-3f9187667089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  6 14:06:56 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   65C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEPCt2YqAZW5",
    "outputId": "c8d73437-59d5-4dcb-9d80-bf7d3577e348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuEruD4f5sYI"
   },
   "source": [
    "### Repository\n",
    "\n",
    "Mount drive, clone repo, navigate to repo, and change working directory to access repo files. **Run ONCE per computing session.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGeFdZYKz05l",
    "outputId": "208946e1-3e62-4e0c-86af-e0b21c5e417b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/MyDrive\n",
      "Repo already present. Updating...\n",
      "/content/gdrive/MyDrive/FANet_Evaluation\n",
      "From https://github.com/goromal/FANet_Evaluation\n",
      " * branch            main       -> FETCH_HEAD\n",
      "Already up to date.\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd gdrive/MyDrive/\n",
    "if not os.path.exists('FANet_Evaluation'):\n",
    "  print('Repo not present. Cloning...')\n",
    "  ! git clone https://github.com/goromal/FANet_Evaluation.git\n",
    "  %cd FANet_Evaluation/\n",
    "else:\n",
    "  print('Repo already present. Updating...')\n",
    "  %cd FANet_Evaluation/\n",
    "  ! git pull origin main\n",
    "from model.test_model import *\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcYzRVcU5cqE"
   },
   "source": [
    "### Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGy-tLG03WtY",
    "outputId": "ecb1bfb8-0ef4-4669-ca2f-0edc3e50ebb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting oyaml\n",
      "  Downloading https://files.pythonhosted.org/packages/37/aa/111610d8bf5b1bb7a295a048fc648cec346347a8b0be5881defd2d1b4a52/oyaml-1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from oyaml) (3.13)\n",
      "Installing collected packages: oyaml\n",
      "Successfully installed oyaml-1.0\n",
      "Collecting torchstat\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/fe/f483b907ca80c90f189cd892bb2ce7b2c256010b30314bbec4fc17d1b5f1/torchstat-0.0.7-py3-none-any.whl\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.8.1+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.19.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.1.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchstat) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchstat) (1.15.0)\n",
      "Installing collected packages: torchstat\n",
      "Successfully installed torchstat-0.0.7\n"
     ]
    }
   ],
   "source": [
    "! pip install oyaml\n",
    "! pip install torchstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v90XgWEKGLGk"
   },
   "source": [
    "## FANet-18 Initial FPS esting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krFI5O1nGRnM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import oyaml as yaml\n",
    "from torchstat import stat\n",
    "import time,os\n",
    "\n",
    "from model.fanet import FANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VVvvTik_Mk-",
    "outputId": "c2d59973-7774-4e93-e42d-a6f6e0812171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FANet-18 Performance (FPS): 40.201780\n"
     ]
    }
   ],
   "source": [
    "network = FANet(backbone='resnet18')\n",
    "network.cuda()\n",
    "network.eval()\n",
    "t_cnt = 0.0\n",
    "with torch.no_grad():\n",
    "  input = torch.rand((1,3,1024,2048)).cuda()\n",
    "  \n",
    "  torch.cuda.synchronize()\n",
    "  x = network(input)\n",
    "  x = network(input)\n",
    "  \n",
    "  torch.cuda.synchronize()\n",
    "  torch.cuda.synchronize()\n",
    "  start_ts = time.time()\n",
    "\n",
    "  for i in range(100):\n",
    "    x = network(input)\n",
    "  \n",
    "  torch.cuda.synchronize()\n",
    "  end_ts = time.time()\n",
    "\n",
    "  t_cnt = end_ts-start_ts\n",
    "\n",
    "print('FANet-18 Performance (FPS): %f' % (100.0/t_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGarf8rjjcZu"
   },
   "source": [
    "# Evaluation Pipeline Training Decomposition\n",
    "\n",
    "This is how they train a model, from start to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3P-rxfRFjeUP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/gdrive/MyDrive/FANet_Evaluation/evaluation') # so that the evaluation pipeline's internal imports work\n",
    "import tensorflow as tf\n",
    "from evaluation.utils.params import get_params\n",
    "from evaluation.utils.dirs import create_exp_dirs\n",
    "from evaluation.utils.misc import timeit\n",
    "import scipy.misc as misc # for image resizing\n",
    "from tqdm import tqdm # progress bar visualization\n",
    "import time # for timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "j1WgfBS9lLnp",
    "outputId": "e57e5b53-7af6-4c87-947d-db59d5ff37cc"
   },
   "outputs": [],
   "source": [
    "# Usable Models\n",
    "from evaluation.models.dilation_mobilenet import DilationMobileNet # << using this network as an example\n",
    "# etc...there's like 15 of them\n",
    "\n",
    "# Metrics for measuring performance (mIoU, etc.)\n",
    "from evaluation.metrics.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument class to instantiate a model\n",
    "class ModelTrainArgs(object):\n",
    "    def __init__(self):\n",
    "        # MODEL ARGS\n",
    "        self.img_width = 1024\n",
    "        self.img_height = 512\n",
    "        self.num_channels = 3 # 3 channels for color images\n",
    "        # data dir contains pre-processed weights.npy, X_train.npy, Y_train.npy, X_val.npy, Y_val.npy\n",
    "        self.data_dir = '/content/gdrive/MyDrive/full_cityscapes_res' # DATA LOCATED IN \"My Drive/full_cityscapes_res\"\n",
    "        self.weighted_loss = True\n",
    "        self.batch_size = 4\n",
    "        self.learning_rate = 0.0001\n",
    "        \n",
    "        # TRAIN ARGS\n",
    "        self.data_mode = \"experiment\"\n",
    "        self.num_classes = 20 # for CityScapes\n",
    "        self.test_every = 10 # validation performed every 10 training epochs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "args = ModelTrainArgs()\n",
    "\n",
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create the sess\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True))\n",
    "\n",
    "# Create Model class and \"build\" it\n",
    "with sess.as_default():\n",
    "    with tf.variable_scope('network') as scope:\n",
    "        model = DilationMobileNet(args)\n",
    "        model.build()\n",
    "\n",
    "# Instantiate training components\n",
    "sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "train_data = None\n",
    "train_data_len = None\n",
    "val_data = None\n",
    "val_data_len = None\n",
    "num_iterations_training_per_epoch = None\n",
    "num_iterations_validation_per_epoch = None\n",
    "metrics = Metrics(args.num_classes)\n",
    "\n",
    "# Training batch generator\n",
    "def train_generator():\n",
    "    global args, num_iterations_training_per_epoch, train_data_len, train_data\n",
    "    start = 0\n",
    "    idx = np.random.choice(train_data_len, num_iterations_training_per_epoch * args.batch_size, replace=True)\n",
    "    while True:\n",
    "        # select the mini_batches\n",
    "        mask = idx[start:start + args.batch_size]\n",
    "        x_batch = train_data['X'][mask]\n",
    "        y_batch = train_data['Y'][mask]\n",
    "\n",
    "        # update start idx\n",
    "        start += args.batch_size\n",
    "\n",
    "        yield x_batch, y_batch\n",
    "\n",
    "        if start >= train_data_len:\n",
    "            return\n",
    "\n",
    "# Load training and validation data\n",
    "print(\"Loading Training data..\")\n",
    "train_data_wrongsize = {'X': np.load(args.data_dir + \"X_train.npy\"), 'Y': np.load(args.data_dir + \"Y_train.npy\")}\n",
    "X = []\n",
    "Y = []\n",
    "train_data = dict()\n",
    "for i in range(train_data_wrongsize['X'].shape[0]):\n",
    "    X.append(misc.imresize(train_data_wrongsize['X'][i, ...], (args.img_height, args.img_width)))\n",
    "    Y.append(misc.imresize(train_data_wrongsize['Y'][i, ...], (args.img_height, args.img_width), 'nearest'))\n",
    "train_data['X'] = np.asarray(X)\n",
    "train_data['Y'] = np.asarray(Y)\n",
    "train_data_len = train_data['X'].shape[0]\n",
    "num_iterations_training_per_epoch = (train_data_len + args.batch_size - 1) // args.batch_size\n",
    "print(\"Train-shape-x -- \" + str(train_data['X'].shape) + \" \" + str(train_data_len))\n",
    "print(\"Train-shape-y -- \" + str(train_data['Y'].shape))\n",
    "print(\"Num of iterations on training data in one epoch -- \" + str(num_iterations_training_per_epoch))\n",
    "print(\"Training data is loaded\")\n",
    "\n",
    "print(\"Loading Validation data..\")\n",
    "val_data = {'X': np.load(args.data_dir + \"X_val.npy\"), 'Y': np.load(args.data_dir + \"Y_val.npy\")}\n",
    "val_data['Y_large'] = self.val_data['Y']\n",
    "val_data_len = val_data['X'].shape[0] - val_data['X'].shape[0] % args.batch_size\n",
    "num_iterations_validation_per_epoch = (val_data_len + args.batch_size - 1) // args.batch_size\n",
    "print(\"Val-shape-x -- \" + str(val_data['X'].shape) + \" \" + str(val_data_len))\n",
    "print(\"Val-shape-y -- \" + str(val_data['Y'].shape))\n",
    "print(\"Num of iterations on validation data in one epoch -- \" + str(num_iterations_validation_per_epoch))\n",
    "print(\"Validation data is loaded\")\n",
    "\n",
    "# Train\n",
    "print(\"Training mode will begin NOW ..\")\n",
    "for cur_epoch in range(self.model.global_epoch_tensor.eval(self.sess) + 1, self.args.num_epochs + 1, 1):\n",
    "\n",
    "    # init tqdm and get the epoch value\n",
    "    tt = tqdm(train_generator(), total=num_iterations_training_per_epoch, desc=\"epoch-\" + str(cur_epoch) + \"-\")\n",
    "\n",
    "    # init the current iterations\n",
    "    cur_iteration = 0\n",
    "\n",
    "    # init acc and loss lists\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    # loop by the number of iterations\n",
    "    for x_batch, y_batch in tt:\n",
    "\n",
    "        # get the cur_it for the summary\n",
    "        cur_it = model.global_step_tensor.eval(sess)\n",
    "\n",
    "        # Feed data into the network\n",
    "        feed_dict = {model.x_pl: x_batch,\n",
    "                     model.y_pl: y_batch,\n",
    "                     model.is_training: True}\n",
    "\n",
    "        # Run the feed forward but the last iteration finalize what you want to do\n",
    "        if cur_iteration < num_iterations_training_per_epoch - 1:\n",
    "\n",
    "            # run the feed_forward\n",
    "            _, loss, acc, summaries_merged = sess.run(\n",
    "                        [model.train_op, model.loss, model.accuracy, model.merged_summaries],\n",
    "                        feed_dict=feed_dict)\n",
    "            # log loss and acc\n",
    "            loss_list += [loss]\n",
    "            acc_list += [acc]\n",
    "\n",
    "        else:\n",
    "            # run the feed_forward\n",
    "            _, loss, acc, summaries_merged, segmented_imgs = self.sess.run(\n",
    "                            [model.train_op, model.loss, model.accuracy,\n",
    "                             model.merged_summaries, model.segmented_summary],\n",
    "                             feed_dict=feed_dict)\n",
    "\n",
    "            # log loss and acc\n",
    "            loss_list += [loss]\n",
    "            acc_list += [acc]\n",
    "            total_loss = np.mean(loss_list)\n",
    "            total_acc = np.mean(acc_list)\n",
    "\n",
    "            # Update the Global step\n",
    "            model.global_step_assign_op.eval(session=sess, feed_dict={model.global_step_input: cur_it + 1})\n",
    "\n",
    "            # Update the Cur Epoch tensor\n",
    "            # it is the last thing because if it is interrupted it repeat this\n",
    "            model.global_epoch_assign_op.eval(session=sess, feed_dict={model.global_epoch_input: cur_epoch + 1})\n",
    "\n",
    "            # print in console\n",
    "            tt.close()\n",
    "            print(\"epoch-\" + str(cur_epoch) + \"-\" + \"loss:\" + str(total_loss) + \"-\" + \" acc:\" + str(total_acc)[:6])\n",
    "\n",
    "            # Break the loop to finalize this epoch\n",
    "            break\n",
    "\n",
    "        # Update the Global step\n",
    "        model.global_step_assign_op.eval(session=sess, feed_dict={model.global_step_input: cur_it + 1})\n",
    "\n",
    "        # update the cur_iteration\n",
    "        cur_iteration += 1\n",
    "\n",
    "    # Test the model on validation set\n",
    "    if cur_epoch % args.test_every == 0:\n",
    "        step = model.global_step_tensor.eval(sess)\n",
    "        epoch = model.global_epoch_tensor.eval(sess)\n",
    "        print(\"Validation at step:\" + str(step) + \" at epoch:\" + str(epoch) + \" ..\")\n",
    "\n",
    "        # init tqdm and get the epoch value\n",
    "        tt = tqdm(range(num_iterations_validation_per_epoch), total=num_iterations_validation_per_epoch,\n",
    "                  desc=\"Val-epoch-\" + str(epoch) + \"-\")\n",
    "\n",
    "        # init acc and loss lists\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        inf_list = []\n",
    "\n",
    "        # idx of minibatch\n",
    "        idx = 0\n",
    "\n",
    "        # reset metrics\n",
    "        metrics.reset()\n",
    "\n",
    "        # get the maximum iou to compare with and save the best model\n",
    "        max_iou = model.best_iou_tensor.eval(self.sess)\n",
    "\n",
    "        # loop by the number of iterations\n",
    "        for cur_iteration in tt:\n",
    "            # load minibatches\n",
    "            x_batch = val_data['X'][idx:idx + args.batch_size]\n",
    "            y_batch = val_data['Y'][idx:idx + args.batch_size]\n",
    "\n",
    "            # update idx of minibatch\n",
    "            idx += args.batch_size\n",
    "\n",
    "            # Feed this variables to the network\n",
    "            feed_dict = {model.x_pl: x_batch,\n",
    "                         model.y_pl: y_batch,\n",
    "                         model.is_training: False}\n",
    "\n",
    "            # Run the feed forward but the last iteration finalize what you want to do\n",
    "            if cur_iteration < num_iterations_validation_per_epoch - 1:\n",
    "\n",
    "                start = time.time()\n",
    "                # run the feed_forward\n",
    "\n",
    "                out_argmax, loss, acc, summaries_merged = sess.run(\n",
    "                    [model.out_argmax, model.loss, model.accuracy, model.merged_summaries],\n",
    "                    feed_dict=feed_dict)\n",
    "\n",
    "                end = time.time()\n",
    "                # log loss and acc\n",
    "                loss_list += [loss]\n",
    "                acc_list += [acc]\n",
    "                inf_list += [end - start]\n",
    "\n",
    "                # log metrics\n",
    "                metrics.update_metrics_batch(out_argmax, y_batch)\n",
    "\n",
    "            else:\n",
    "                start = time.time()\n",
    "                # run the feed_forward\n",
    "                out_argmax, acc, segmented_imgs = sess.run(\n",
    "                        [test_model.out_argmax, test_model.accuracy, test_model.segmented_summary],\n",
    "                        feed_dict=feed_dict)\n",
    "\n",
    "                end = time.time()\n",
    "                # log loss and acc\n",
    "                acc_list += [acc]\n",
    "                inf_list += [end - start]\n",
    "                # log metrics\n",
    "                metrics.update_metrics_batch(out_argmax, y_batch)\n",
    "                # mean over batches\n",
    "                total_acc = np.mean(acc_list)\n",
    "                mean_iou = metrics.compute_final_metrics(num_iterations_validation_per_epoch)\n",
    "                mean_iou_arr = metrics.iou\n",
    "                mean_inference = str(np.mean(inf_list)) + '-seconds'\n",
    "\n",
    "                # print in console\n",
    "                tt.close()\n",
    "                print(\"Val-epoch-\" + str(epoch) + \"-\" +\n",
    "                      \"acc:\" + str(total_acc)[:6] + \"-mean_iou:\" + str(mean_iou))\n",
    "                print(\"Last_max_iou: \" + str(max_iou))\n",
    "                if mean_iou > max_iou:\n",
    "                    print(\"This validation got a new best iou. so we will save this one\")\n",
    "                    # Set the new maximum\n",
    "                    model.best_iou_assign_op.eval(session=sess, feed_dict={model.best_iou_input: mean_iou})\n",
    "                else:\n",
    "                    print(\"Hmm, not the best validation epoch :/..\")\n",
    "                break\n",
    "\n",
    "                # Break the loop to finalize this epoch\n",
    "        \n",
    "\n",
    "# Finish session\n",
    "self.sess.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "fanet_eval_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
