{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OwoEgKvm3cjE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goromal/FANet_Evaluation/blob/main/fanet_eval_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvVGRtJx3XgV"
      },
      "source": [
        "# FANet Evaluation - 6.862 Project\n",
        "\n",
        "\n",
        "\n",
        "*   David Elatov\n",
        "*   Dayne Howard\n",
        "*   Andrew Torgesen\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwoEgKvm3cjE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ajqG5KQ_kHn"
      },
      "source": [
        "### CUDA\n",
        "\n",
        "1. Go to **Menu > Runtime > Change runtime type** and make sure that GPU is enabled.\n",
        "2. Run the commands below to ensure that the GPU (and CUDA) is operational."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pZ2TKFFACfl",
        "outputId": "31fed509-feba-46b6-b34a-37fe76344dd7"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr  2 23:59:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEPCt2YqAZW5",
        "outputId": "f38d5c9b-9ffa-49c8-a508-ff71cd0b1158"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuEruD4f5sYI"
      },
      "source": [
        "### Repository\n",
        "\n",
        "Mount drive, clone repo, navigate to repo, and change working directory to access repo files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGeFdZYKz05l",
        "outputId": "82609ed7-1d02-482c-9742-e343cbbf09e4"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/\n",
        "if not os.path.exists('FANet_Evaluation'):\n",
        "  print('Repo not present. Cloning...')\n",
        "  ! git clone https://github.com/goromal/FANet_Evaluation.git\n",
        "else:\n",
        "  print('Repo already present.')\n",
        "%cd FANet_Evaluation/\n",
        "from model.test_model import *\n",
        "test()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive\n",
            "Repo already present.\n",
            "/content/gdrive/MyDrive/FANet_Evaluation\n",
            "SUCCESS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcYzRVcU5cqE"
      },
      "source": [
        "### Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGy-tLG03WtY",
        "outputId": "ecb1bfb8-0ef4-4669-ca2f-0edc3e50ebb9"
      },
      "source": [
        "! pip install oyaml\n",
        "! pip install torchstat"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting oyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/37/aa/111610d8bf5b1bb7a295a048fc648cec346347a8b0be5881defd2d1b4a52/oyaml-1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from oyaml) (3.13)\n",
            "Installing collected packages: oyaml\n",
            "Successfully installed oyaml-1.0\n",
            "Collecting torchstat\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/fe/f483b907ca80c90f189cd892bb2ce7b2c256010b30314bbec4fc17d1b5f1/torchstat-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchstat) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchstat) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchstat) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchstat) (1.15.0)\n",
            "Installing collected packages: torchstat\n",
            "Successfully installed torchstat-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v90XgWEKGLGk"
      },
      "source": [
        "## FANet-18 Initial FPS esting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krFI5O1nGRnM"
      },
      "source": [
        "import torch\n",
        "import oyaml as yaml\n",
        "from torchstat import stat\n",
        "import time,os\n",
        "\n",
        "from model.fanet import FANet"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VVvvTik_Mk-",
        "outputId": "c2d59973-7774-4e93-e42d-a6f6e0812171"
      },
      "source": [
        "network = FANet(backbone='resnet18')\n",
        "network.cuda()\n",
        "network.eval()\n",
        "t_cnt = 0.0\n",
        "with torch.no_grad():\n",
        "  input = torch.rand((1,3,1024,2048)).cuda()\n",
        "  \n",
        "  torch.cuda.synchronize()\n",
        "  x = network(input)\n",
        "  x = network(input)\n",
        "  \n",
        "  torch.cuda.synchronize()\n",
        "  torch.cuda.synchronize()\n",
        "  start_ts = time.time()\n",
        "\n",
        "  for i in range(100):\n",
        "    x = network(input)\n",
        "  \n",
        "  torch.cuda.synchronize()\n",
        "  end_ts = time.time()\n",
        "\n",
        "  t_cnt = end_ts-start_ts\n",
        "\n",
        "print('FANet-18 Performance (FPS): %f' % (100.0/t_cnt))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FANet-18 Performance (FPS): 40.201780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D37L1J3sBeN0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}